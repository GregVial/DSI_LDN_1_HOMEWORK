{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework w05d04 - Feature selection\n",
    "\n",
    "\n",
    "### Read in the Wisconsin Breast Cancer Dataset\n",
    "\n",
    "### Assign the columns\n",
    "\n",
    "The attributes below will be the columns of the dataset.\n",
    "  \n",
    "Attribute                     \n",
    "\n",
    "1. Sample code number [subject ID]\n",
    "1. Class\n",
    "1. Cell nucleus mean radius\n",
    "1. Cell nucleus SE radius\n",
    "1. Cell nucleus worst radius\n",
    "1. Texture mean\n",
    "1. Texture SE\n",
    "1. Texture worst\n",
    "1. Perimeter mean\n",
    "1. Perimeter SE\n",
    "1. Perimeter worst\n",
    "1. Area mean\n",
    "1. Area SE\n",
    "1. Area worst\n",
    "1. Smoothness mean\n",
    "1. Smoothness SE\n",
    "1. Smoothness worst\n",
    "1. Compactness mean\n",
    "1. Compactness SE\n",
    "1. Compactness worst\n",
    "1. Concavity mean\n",
    "1. Concavity SE\n",
    "1. Concavity worst\n",
    "1. Concave points mean\n",
    "1. Concave points SE\n",
    "1. Concave points worst\n",
    "1. Symmetry mean\n",
    "1. Symmetry SE\n",
    "1. Symmetry worst\n",
    "1. Fractal dimension mean\n",
    "1. Fractal dimension SE\n",
    "1. Fractal dimension worst\n",
    "\n",
    "The column names are taken from the dataset info file.\n",
    "For more information check out the information file: wdbc.names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: malignant, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleus_mean</th>\n",
       "      <th>nucleus_se</th>\n",
       "      <th>nucleus_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_pts_mean</th>\n",
       "      <th>concave_pts_se</th>\n",
       "      <th>concave_pts_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dim_mean</th>\n",
       "      <th>fractal_dim_se</th>\n",
       "      <th>fractal_dim_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nucleus_mean  nucleus_se  nucleus_worst  texture_mean  texture_se  \\\n",
       "0         17.99       10.38         122.80        1001.0     0.11840   \n",
       "1         20.57       17.77         132.90        1326.0     0.08474   \n",
       "2         19.69       21.25         130.00        1203.0     0.10960   \n",
       "3         11.42       20.38          77.58         386.1     0.14250   \n",
       "4         20.29       14.34         135.10        1297.0     0.10030   \n",
       "\n",
       "   texture_worst  perimeter_mean  perimeter_se  perimeter_worst  area_mean  \\\n",
       "0        0.27760          0.3001       0.14710           0.2419    0.07871   \n",
       "1        0.07864          0.0869       0.07017           0.1812    0.05667   \n",
       "2        0.15990          0.1974       0.12790           0.2069    0.05999   \n",
       "3        0.28390          0.2414       0.10520           0.2597    0.09744   \n",
       "4        0.13280          0.1980       0.10430           0.1809    0.05883   \n",
       "\n",
       "         ...          concavity_worst  concave_pts_mean  concave_pts_se  \\\n",
       "0        ...                    25.38             17.33          184.60   \n",
       "1        ...                    24.99             23.41          158.80   \n",
       "2        ...                    23.57             25.53          152.50   \n",
       "3        ...                    14.91             26.50           98.87   \n",
       "4        ...                    22.54             16.67          152.20   \n",
       "\n",
       "   concave_pts_worst  symmetry_mean  symmetry_se  symmetry_worst  \\\n",
       "0             2019.0         0.1622       0.6656          0.7119   \n",
       "1             1956.0         0.1238       0.1866          0.2416   \n",
       "2             1709.0         0.1444       0.4245          0.4504   \n",
       "3              567.7         0.2098       0.8663          0.6869   \n",
       "4             1575.0         0.1374       0.2050          0.4000   \n",
       "\n",
       "   fractal_dim_mean  fractal_dim_se  fractal_dim_worst  \n",
       "0            0.2654          0.4601            0.11890  \n",
       "1            0.1860          0.2750            0.08902  \n",
       "2            0.2430          0.3613            0.08758  \n",
       "3            0.2575          0.6638            0.17300  \n",
       "4            0.1625          0.2364            0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, recall_score, precision_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\", header=None)\n",
    "\n",
    "column_names = ['id','malignant',\n",
    "                'nucleus_mean','nucleus_se','nucleus_worst',\n",
    "                'texture_mean','texture_se','texture_worst',\n",
    "                'perimeter_mean','perimeter_se','perimeter_worst',\n",
    "                'area_mean','area_se','area_worst',\n",
    "                'smoothness_mean','smoothness_se','smoothness_worst',\n",
    "                'compactness_mean','compactness_se','compactness_worst',\n",
    "                'concavity_mean','concavity_se','concavity_worst',\n",
    "                'concave_pts_mean','concave_pts_se','concave_pts_worst',\n",
    "                'symmetry_mean','symmetry_se','symmetry_worst',\n",
    "                'fractal_dim_mean','fractal_dim_se','fractal_dim_worst']\n",
    "\n",
    "df.columns = column_names\n",
    "\n",
    "# Define the feature matrix X\n",
    "X = df.iloc[:,2:]\n",
    "\n",
    "#Define the response y and recode it numerically\n",
    "y = df.malignant\n",
    "y = y.map(lambda x: 0 if x == \"B\" else 1)\n",
    "print y.head()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use the standard scaler to transform the feature matrix X, put the output into a pandas data frame and assign the appropriate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleus_mean</th>\n",
       "      <th>nucleus_se</th>\n",
       "      <th>nucleus_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_pts_mean</th>\n",
       "      <th>concave_pts_se</th>\n",
       "      <th>concave_pts_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dim_mean</th>\n",
       "      <th>fractal_dim_se</th>\n",
       "      <th>fractal_dim_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nucleus_mean  nucleus_se  nucleus_worst  texture_mean  texture_se  \\\n",
       "0      1.097064   -2.073335       1.269934      0.984375    1.568466   \n",
       "1      1.829821   -0.353632       1.685955      1.908708   -0.826962   \n",
       "2      1.579888    0.456187       1.566503      1.558884    0.942210   \n",
       "3     -0.768909    0.253732      -0.592687     -0.764464    3.283553   \n",
       "4      1.750297   -1.151816       1.776573      1.826229    0.280372   \n",
       "\n",
       "   texture_worst  perimeter_mean  perimeter_se  perimeter_worst  area_mean  \\\n",
       "0       3.283515        2.652874      2.532475         2.217515   2.255747   \n",
       "1      -0.487072       -0.023846      0.548144         0.001392  -0.868652   \n",
       "2       1.052926        1.363478      2.037231         0.939685  -0.398008   \n",
       "3       3.402909        1.915897      1.451707         2.867383   4.910919   \n",
       "4       0.539340        1.371011      1.428493        -0.009560  -0.562450   \n",
       "\n",
       "         ...          concavity_worst  concave_pts_mean  concave_pts_se  \\\n",
       "0        ...                 1.886690         -1.359293        2.303601   \n",
       "1        ...                 1.805927         -0.369203        1.535126   \n",
       "2        ...                 1.511870         -0.023974        1.347475   \n",
       "3        ...                -0.281464          0.133984       -0.249939   \n",
       "4        ...                 1.298575         -1.466770        1.338539   \n",
       "\n",
       "   concave_pts_worst  symmetry_mean  symmetry_se  symmetry_worst  \\\n",
       "0           2.001237       1.307686     2.616665        2.109526   \n",
       "1           1.890489      -0.375612    -0.430444       -0.146749   \n",
       "2           1.456285       0.527407     1.082932        0.854974   \n",
       "3          -0.550021       3.394275     3.893397        1.989588   \n",
       "4           1.220724       0.220556    -0.313395        0.613179   \n",
       "\n",
       "   fractal_dim_mean  fractal_dim_se  fractal_dim_worst  \n",
       "0          2.296076        2.750622           1.937015  \n",
       "1          1.087084       -0.243890           0.281190  \n",
       "2          1.955000        1.152255           0.201391  \n",
       "3          2.175786        6.046041           4.935010  \n",
       "4          0.729259       -0.868353          -0.397100  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "Xt = StandardScaler().fit_transform(X)\n",
    "Xt = pd.DataFrame(Xt,columns = column_names[2:])\n",
    "Xt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use best subset selection to determine the 5 best predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nucleus_worst', 'perimeter_se', 'concavity_worst', 'concave_pts_se', 'fractal_dim_mean']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(Xt,y)\n",
    "mask = selector.get_support(indices=True)\n",
    "print(Xt[mask].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use percentile based feature selection, vary the percentile by 5% steps and indicate which features are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile 5, selected features: 2\n",
      "Percentile 10, selected features: 3\n",
      "Percentile 15, selected features: 5\n",
      "Percentile 20, selected features: 6\n",
      "Percentile 25, selected features: 8\n",
      "Percentile 30, selected features: 9\n",
      "Percentile 35, selected features: 11\n",
      "Percentile 40, selected features: 12\n",
      "Percentile 45, selected features: 14\n",
      "Percentile 50, selected features: 15\n",
      "Percentile 55, selected features: 16\n",
      "Percentile 60, selected features: 18\n",
      "Percentile 65, selected features: 19\n",
      "Percentile 70, selected features: 21\n",
      "Percentile 75, selected features: 22\n",
      "Percentile 80, selected features: 24\n",
      "Percentile 85, selected features: 25\n",
      "Percentile 90, selected features: 27\n",
      "Percentile 95, selected features: 28\n",
      "Percentile 100, selected features: 30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile#, VarianceThreshold, f_classif\n",
    "\n",
    "# Use e.g.\n",
    "for p in range(5,101,5):\n",
    "    selector = SelectPercentile(f_classif, percentile=p)\n",
    "    selector.fit(Xt,y)\n",
    "    mask = selector.get_support(indices=True)\n",
    "    print(\"Percentile %d, selected features: %d\" % (p, len(mask)))\n",
    "    #print(Xt[mask].columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use feature ranking with recursive feature elimination and cross-validated selection for feature selection. Vary the number of cross validations between 2 and 10. How does the number of features change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Folds 2, selected features: 23\n",
      "# Folds 3, selected features: 23\n",
      "# Folds 4, selected features: 30\n",
      "# Folds 5, selected features: 30\n",
      "# Folds 6, selected features: 25\n",
      "# Folds 7, selected features: 17\n",
      "# Folds 8, selected features: 20\n",
      "# Folds 9, selected features: 27\n",
      "# Folds 10, selected features: 30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# use e.g. RFECV(estimator, step=1,cv=5)\n",
    "for cv in range(2,11,1):\n",
    "    selector = RFECV(LogisticRegression(),step=1,cv=cv)\n",
    "    selector.fit(Xt,y)\n",
    "    mask = selector.get_support(indices=True)\n",
    "    print(\"# Folds %d, selected features: %d\" % (cv, len(mask)))\n",
    "    #print(Xt[mask].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usualy recommanded number of cross validation folds, 5 and 10, correspond to the highest number of features selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feed RFECV with cv=5 into grid search CV with logistic regression. Vary the regularisation parameters C and the penalty (l1 or l2) and obtain the scores for the best model. Obtain the regression coefficients and determine the five with largest absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "selector = RFECV(estimator, step=1, cv=5)\n",
    "\n",
    "params = {'estimator__penalty':['l1','l2'],\n",
    "'estimator__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(selector, param_grid = params)\n",
    "model_fit = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 10, 'estimator__penalty': 'l1'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
