{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report: Predicting titanic survival\n",
    "#### Gr√©gory Vial\n",
    "#### November 13th, 2016\n",
    "\n",
    "### Executive summary\n",
    "By studying some characteristics of titanic survivors, if given a new individual who was also on the Titanic, we are able to predict whether he died of survived the shipwreck with an accuracy of nearly 78%.\n",
    "\n",
    "The model is robust and can easily be extended to other emergency situations. Given a past crisis situation (earthquake, bombing, accident), if we can study its features and that of people invovled in it, then we are convinced that we  make predictions that would have a high accuracy for other similar situations.\n",
    "\n",
    "### Introduction\n",
    "The Titanic and its tragic fate are one of the most famous civil shipwreck in history. \n",
    "\n",
    "Leaving Southampton in Great Britain on 10th April 1912, it hit an iceberg 4 days later and sunk on 15th April. On board were more than 3300 passengers (exact number varies according to sources), including nearly 900 crew members.\n",
    "\n",
    "On board there were only 20 lifeboars, sufficient for 1178 people, so about a third of the total number of passengers. There were an estimate of 705 survivors.\n",
    "\n",
    "In this project we aim at studying features of passengers such as their age, sex, class, port of embarkments, number of family members of board etc, and to predict whether the passenger survived or not.\n",
    "\n",
    "### Method\n",
    "We built several models using various classification algorithms. Each model was trained with a subset of the passengers obtained on [Kaggle](http://www.kaggle.com), a data science contest website.\n",
    "\n",
    "We then tested the model with another subset of the passengers and compared our survival predictions with actual survival. Each time we checked various criteria:\n",
    "* Accuracy: the proportion of right predictions\n",
    "* Precision: out of all predicted survivors, how many were actual survivors\n",
    "* Recall: out of all survivors, how many did indeed predict as survivors\n",
    "\n",
    "Finally, after comparing our models with this test set, we run a final check using a validation set (again another subset of the passengers that we didn't use before). This gave us a final confirmation of our best model.\n",
    "\n",
    "### Results\n",
    "Here are the algorithms we tried and the precision/recall for test set, and accuracy they achieved using the validation set:\n",
    "\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-9hbo\">Algorithm</th>\n",
    "    <th class=\"tg-9hbo\">Precision (test)</th>\n",
    "    <th class=\"tg-9hbo\">Recall (test)</th>\n",
    "    <th class=\"tg-9hbo\">Accuracy(validation)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">Logistic Regression</td>\n",
    "    <td class=\"tg-yw4l\">78%</td>\n",
    "    <td class=\"tg-yw4l\">57%</td>\n",
    "    <td class=\"tg-yw4l\">77%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">K Nearest Neighbours</td>\n",
    "    <td class=\"tg-yw4l\">64%</td>\n",
    "    <td class=\"tg-yw4l\">62%</td>\n",
    "    <td class=\"tg-yw4l\">64%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">Decision Tree</td>\n",
    "    <td class=\"tg-yw4l\">77%</td>\n",
    "    <td class=\"tg-yw4l\">60%</td>\n",
    "    <td class=\"tg-yw4l\">78%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">Bagging</td>\n",
    "    <td class=\"tg-yw4l\">72%</td>\n",
    "    <td class=\"tg-yw4l\">63%</td>\n",
    "    <td class=\"tg-yw4l\">50%</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "### Interpretation\n",
    "The result show clear superiority of Logitic Regression and Decision Trees over KNN and Bagging, as they yield much better results for all criteria.\n",
    "However there is not obvious reason to preger Logistic Regression over Decision Tree or vice versa. The former will be slightly better at being right when predicting that someone survived, whereas the latter will be better at identifying the highest ratio of survivors. Depending on what from wrongly predicted survival or lower ratio of actual surivors identified we want to favour when predicting, we may chose one or another.\n",
    "\n",
    "### Conclusion\n",
    "Our study has shown that with a limited set of information about Titanic passengers, we were able to predict with an accuracy of 78% whether they survived or not the shipwreck.\n",
    "\n",
    "Out of 4 algorithms studied, 2 have been ruled out due to poor performances, and 2 have been retained and can be used based on the type of results we want to achieve:\n",
    "* Logistic regression tends to be better at predicting that someone survived if it actually survived\n",
    "* Decision tree tends to be better at capturing the highest proportion of survivors\n",
    "\n",
    "\n",
    "### Recommendations\n",
    "Some data made available to us was not used in this study, such as the name of the passengers. Names contain titles \"Mr\", \"Miss\", \"Mrs\", \"Rev\", \"Major\" etc that may be meaninful to help us with our predictions.\n",
    "\n",
    "As a next step we should consider including them in a more advanced model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
